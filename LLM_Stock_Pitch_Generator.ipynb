{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e02ac5-dedb-4317-a749-0f8d6d5ae9b4",
   "metadata": {},
   "source": [
    "# A Full Business Solution for a Investment Management Company\n",
    "\n",
    "The following script allows the user to do the following:\n",
    "\n",
    "1) Retrive all the links that are useful to the target company\n",
    "2) Generate an automatic 1 page pitch on why the company should be a \"Buy\" for an investment management firm\n",
    "\n",
    "The user also has the flexibility in choosing out of three models for each task. They can choose from the following:\n",
    "\n",
    "- gpt-4o-mini\n",
    "- claude-3-haiku\n",
    "- deepseek-chat\n",
    "\n",
    "This allows the user to not have to rely on just one Agent but can choose from a list for both tasks adding extra flexibility.\n",
    "\n",
    "Finally, this script uses the Gradio UI so anyone can have access to the public URL. The UI will also loads a webpage (html format) to a separate tab for the user to see the final pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7364ec26-a00a-43fc-8d8e-e513f39344ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89c7f7b-f955-4a4c-81d6-c6beba807cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e057455-dda0-46d8-ba57-0c35465292ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b3448b-15d7-4555-aa69-5ee5895c8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44904055-4ca8-48bb-a724-50c2d06bb22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyA4\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6393c82d-7075-4c2c-a4bb-fd42b0486975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8180e016-cf21-4e9b-bfde-b437c40d34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        try:\n",
    "            # Add more comprehensive headers and a timeout\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\",\n",
    "                \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "                \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "                \"Connection\": \"keep-alive\",\n",
    "                \"Upgrade-Insecure-Requests\": \"1\",\n",
    "                \"Sec-Fetch-Dest\": \"document\",\n",
    "                \"Sec-Fetch-Mode\": \"navigate\",\n",
    "                \"Sec-Fetch-Site\": \"none\",\n",
    "                \"Sec-Fetch-User\": \"?1\",\n",
    "                \"Cache-Control\": \"max-age=0\"\n",
    "            }\n",
    "            \n",
    "            # Add a reasonable timeout to prevent hanging\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()  # Raise exception for 4XX/5XX status codes\n",
    "            \n",
    "            self.body = response.content\n",
    "            soup = BeautifulSoup(self.body, 'html.parser')\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            \n",
    "            if soup.body:\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                    irrelevant.decompose()\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"\"\n",
    "                \n",
    "            # More robust link extraction\n",
    "            self.links = []\n",
    "            for link in soup.find_all('a'):\n",
    "                href = link.get('href')\n",
    "                if href:\n",
    "                    # Handle relative URLs properly\n",
    "                    if href.startswith('/'):\n",
    "                        # Parse the base URL to handle relative links\n",
    "                        base_url = urlparse(url)\n",
    "                        full_url = f\"{base_url.scheme}://{base_url.netloc}{href}\"\n",
    "                        self.links.append(full_url)\n",
    "                    elif href.startswith('http'):\n",
    "                        self.links.append(href)\n",
    "                    # Skip javascript: links, mailto: links, etc.\n",
    "                    \n",
    "            print(f\"Successfully processed {url}\")\n",
    "            print(f\"Found {len(self.links)} links\")\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "            # Provide default values on error\n",
    "            self.body = b\"\"\n",
    "            self.title = \"Error fetching page\"\n",
    "            self.text = f\"Could not fetch page content: {str(e)}\"\n",
    "            self.links = []\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8cdee7-9182-43c7-b4c3-55a010c83aa7",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "I will use \"one shot prompting\" in which I provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c72844-6ce7-4c67-900e-35e0645a3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are a link extraction agent. Your task is to extract only the most relevant pages from a company's website that would support writing a professional 1-page investment pitch for institutional investors.\n",
    "\n",
    "Return only a valid JSON object. All keys and string values must use double quotes (\"). Do not include any commentary or extra text.Your output must include:\n",
    "Your output must include:\n",
    "- \"homepage\": the company homepage URL\n",
    "- \"links\": an array of link objects, where each object has:\n",
    "  - \"type\": a category (e.g., \"about page\", \"investor relations page\", etc.)\n",
    "  - \"url\": the full URL\n",
    "\n",
    "Example:\n",
    "Input:\n",
    "[\n",
    "  \"https://acme.com\",\n",
    "  \"https://acme.com/about\",\n",
    "  \"https://acme.com/investor-relations\",\n",
    "  \"https://acme.com/contact\"\n",
    "]\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"homepage\": \"https://acme.com\",\n",
    "  \"links\": [\n",
    "    {\"type\": \"about page\", \"url\": \"https://acme.com/about\"},\n",
    "    {\"type\": \"investor relations page\", \"url\": \"https://acme.com/investor-relations\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Now return the JSON output for the following input:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6510b2ca-d839-4a46-95e4-134e8ffae36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a senior investment analyst assistant tasked with creating a vibrant, high-quality, and professional 1-page stock pitch in Markdown format.\n",
    "\n",
    "This pitch is for institutional investors deciding whether to BUY the stock.\n",
    "\n",
    "Your response must:\n",
    "- Be written in **Markdown**\n",
    "- Include the **company logo** rendered using Clearbit, but only once, directly under the “Company Name and Website” section\n",
    "- Be structured, scannable, and visually appealing using tasteful emojis and bold headers\n",
    "- End with a clear, data-supported investment recommendation\n",
    "\n",
    "### Recommended Sections:\n",
    "- 📌 **Company Name and Website**\n",
    "- ![Company Logo](https://logo.clearbit.com/{domain}) ← Place here\n",
    "- 🏢 **Company Overview**\n",
    "- ⚙️ **Products & Services**\n",
    "- 💼 **Business Model**\n",
    "- 📈 **Growth Strategy**\n",
    "- 🌱 **ESG & Sustainability** (if relevant)\n",
    "- 👥 **Leadership**\n",
    "- 💰 **Financial & Investor Highlights**\n",
    "- 🧠 **Competitive Edge**\n",
    "- ✅ **Final Recommendation**\n",
    "\n",
    "Keep the pitch concise, punchy, and under one page. Use real business reasoning, and end with a firm BUY/HOLD/SELL call.\n",
    "Output only the final Markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "267c45fd-4a4e-424c-9ca5-2c01afa28c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a pitch 1 pager about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f717148a-9552-44aa-9663-d8ef71d5405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(system_prompt, user_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response_stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in response_stream:\n",
    "        # 'delta' is an object, so we can't do delta.get(\"content\")\n",
    "        # Use .content directly (with a fallback)\n",
    "        new_text = chunk.choices[0].delta.content or \"\"\n",
    "        \n",
    "        result += new_text\n",
    "        yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a971ced0-fb97-4ad3-8663-198d821c1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_claude(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Streams completion from Anthropic's Claude using the `anthropic` library.\n",
    "    Yields partial output as it arrives.\n",
    "    \"\"\"\n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd31bc3b-2385-461f-987c-b84fb50140f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek API Key exists and begins sk-\n"
     ]
    }
   ],
   "source": [
    "# Deepseek\n",
    "\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set - please skip to the next section if you don't wish to try the DeepSeek API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1619a96a-49c8-416a-acb5-ce26df0ac0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_deepseek(system_prompt, user_prompt):\n",
    "\n",
    "    deepseek_via_openai_client = OpenAI(\n",
    "    api_key=deepseek_api_key, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    Streams completion from DeepSeek using the OpenAI-compatible client.\n",
    "    Yields partial output as it arrives.\n",
    "    \"\"\"\n",
    "    # Prepare the conversation messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    # Create a streaming completion\n",
    "    response_stream = deepseek_via_openai_client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        stream=True,  # Enable streaming\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # Accumulate tokens and yield progressively\n",
    "    result = \"\"\n",
    "    for chunk in response_stream:\n",
    "        # Check if there's new content in this chunk\n",
    "        if hasattr(chunk.choices[0].delta, \"content\"):\n",
    "            result += chunk.choices[0].delta.content\n",
    "            yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "346bfd16-0d7d-4f26-abf5-39913a6cb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model_and_stream(model_choice, system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    yield partial output from the corresponding streaming function\n",
    "    \"\"\"\n",
    "    # Now you can handle both system_prompt and user_prompt\n",
    "    if model_choice == \"gpt-4o-mini\":\n",
    "        yield from stream_gpt(system_prompt, user_prompt)\n",
    "    elif model_choice == \"claude-3-haiku-20240307\":\n",
    "        yield from stream_claude(system_prompt, user_prompt)\n",
    "    elif model_choice == \"deepseek-chat\":\n",
    "        yield from stream_deepseek(system_prompt, user_prompt)\n",
    "    else:\n",
    "        yield \"Model not recognized.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eaa221c-828d-4973-bb66-d913a0c113d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url, model_choice):\n",
    "    website = Website(url)\n",
    "    \n",
    "    # If we couldn't get any links, return early with a default structure\n",
    "    if not website.links:\n",
    "        print(f\"No links found at {url}\")\n",
    "        return {\"homepage\": url, \"links\": []}\n",
    "    \n",
    "    user_prompt = get_links_user_prompt(website)\n",
    "    \n",
    "    print(f\"Found {len(website.links)} links. Sending to model for filtering...\")\n",
    "    \n",
    "    # Log a sample of the links for debugging\n",
    "    sample_links = website.links[:5]\n",
    "    print(f\"Sample links: {sample_links}\")\n",
    "    \n",
    "    final_text = \"\"\n",
    "    for partial_content in select_model_and_stream(\n",
    "        model_choice,\n",
    "        system_prompt=link_system_prompt,\n",
    "        user_prompt=user_prompt\n",
    "    ):\n",
    "        final_text = partial_content\n",
    "\n",
    "    print(\"DEBUG final_text =\", repr(final_text))\n",
    "    \n",
    "    # Extract JSON from the response\n",
    "    try:\n",
    "        # First try parsing the entire response\n",
    "        result = json.loads(final_text)\n",
    "        print(\"Successfully parsed JSON response\")\n",
    "        return result\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        # If that fails, try to extract JSON using regex\n",
    "        import re\n",
    "        json_pattern = r'(\\{.*\\})'  # Match content between curly braces\n",
    "        match = re.search(json_pattern, final_text, re.DOTALL)\n",
    "        \n",
    "        if match:\n",
    "            try:\n",
    "                result = json.loads(match.group(1))\n",
    "                print(\"Successfully extracted and parsed JSON using regex\")\n",
    "                return result\n",
    "            except json.JSONDecodeError as e2:\n",
    "                print(f\"Extracted content is still not valid JSON: {e2}\")\n",
    "                # If JSON is still invalid, provide a default response\n",
    "                return {\"homepage\": url, \"links\": []}\n",
    "        else:\n",
    "            print(\"No JSON structure found in the response\")\n",
    "            # If no JSON-like pattern found, return a default structure\n",
    "            return {\"homepage\": url, \"links\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e44b1-c198-4a80-ae93-a8483f73eb61",
   "metadata": {},
   "source": [
    "## Second Step: Make the Pitch Deck!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78ccfbdc-1b59-4956-8ef8-d17e43d4d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url, model_choice):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url, model_choice)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91420f65-a916-4eed-9113-948bf9e51182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, homepage_url, domain, relevant_links, page_contents=None):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the company data:\n",
    "\n",
    "- Company Name: {company_name}\n",
    "- Website: {homepage_url}\n",
    "- Domain for logo: {domain}\n",
    "- Relevant pages:\n",
    "{json.dumps(relevant_links, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    if page_contents:\n",
    "        user_prompt += f\"\\n\\n### Page Contents:\\n{page_contents[:20000]}\"\n",
    "\n",
    "    user_prompt += \"\\n\\nPlease use this to write a 1-page Markdown pitch for institutional investors.\"\n",
    "\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be58b6a7-51d6-4dd8-9742-790153a2f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def create_brochure(company_name, homepage_url, relevant_links, model_choice):\n",
    "    # Extract the domain from the homepage URL\n",
    "    domain = urlparse(homepage_url).netloc\n",
    "    \n",
    "    # Build the user prompt\n",
    "    user_prompt = get_brochure_user_prompt(\n",
    "        company_name=company_name,\n",
    "        homepage_url=homepage_url,\n",
    "        domain=domain,\n",
    "        relevant_links=relevant_links\n",
    "    )\n",
    "    \n",
    "    # We'll accumulate the streamed text into final_text\n",
    "    final_text = \"\"\n",
    "    # Stream from whichever model the user selected\n",
    "    for partial_content in select_model_and_stream(\n",
    "        model_choice=model_choice,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt\n",
    "    ):\n",
    "        # Here, we keep overwriting final_text with the latest cumulative partial_content\n",
    "        final_text = partial_content\n",
    "    \n",
    "    # Once streaming is done, we have the entire final text. Now display it as Markdown.\n",
    "    display(Markdown(final_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c8e3b-ecb3-4c85-95dd-e880df39746d",
   "metadata": {},
   "source": [
    "## Finally - A Minor Improvement\n",
    "\n",
    "With a small adjustment, I can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b761333-9493-4069-8ce9-4f2feda48e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_system_prompt = \"\"\"\n",
    "You are a senior investment analyst assistant tasked with creating a vibrant, high-quality, and professional 1-page stock pitch in Markdown format.\n",
    "\n",
    "This pitch is for institutional investors deciding whether to BUY the stock.\n",
    "\n",
    "Your response must:\n",
    "- Be written in **Markdown**\n",
    "- Include the **company logo** rendered using Clearbit, but only once, directly under the “Company Name and Website” section\n",
    "- Be structured, scannable, and visually appealing using tasteful emojis and bold headers\n",
    "- End with a clear, data-supported investment recommendation\n",
    "\n",
    "### Recommended Sections:\n",
    "- 📌 **Company Name and Website**\n",
    "- ![Company Logo](https://logo.clearbit.com/{domain}) ← Place here\n",
    "- 🏢 **Company Overview**\n",
    "- ⚙️ **Products & Services**\n",
    "- 💼 **Business Model**\n",
    "- 📈 **Growth Strategy**\n",
    "- 🌱 **ESG & Sustainability** (if relevant)\n",
    "- 👥 **Leadership**\n",
    "- 💰 **Financial & Investor Highlights**\n",
    "- 🧠 **Competitive Edge**\n",
    "- ✅ **Final Recommendation**\n",
    "\n",
    "Keep the pitch concise, punchy, and under one page. Use real business reasoning, and end with a firm BUY/HOLD/SELL call.\n",
    "Output only the final Markdown.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67b717f8-62f9-4d49-9bac-21b9caaaafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_stream_pitch(company_name: str, homepage_url: str, relevant_links, model_choice: str, save_as_html: bool):\n",
    "    \"\"\"\n",
    "    A generator function for Gradio to produce partial streaming output in Markdown.\n",
    "    Yields partial text as it's generated. After streaming completes,\n",
    "    optionally saves the final text as HTML and opens it in a browser.\n",
    "    \"\"\"\n",
    "    # Parse the URL to extract domain for the logo\n",
    "    domain = urlparse(homepage_url).netloc\n",
    "    \n",
    "    # Create a safe filename from company name or domain\n",
    "    safe_filename = \"\"\n",
    "    if company_name and company_name.strip():\n",
    "        # Use company name if provided\n",
    "        safe_filename = company_name.strip()\n",
    "    else:\n",
    "        # Use domain name as fallback\n",
    "        safe_filename = domain\n",
    "    \n",
    "    # Replace invalid filename characters with underscores\n",
    "    import re\n",
    "    safe_filename = re.sub(r'[\\\\/*?:\"<>|]', \"_\", safe_filename)\n",
    "    safe_filename = safe_filename.replace(' ', '_')\n",
    "    \n",
    "    # Build the user prompt\n",
    "    user_prompt = get_brochure_user_prompt(company_name, homepage_url, domain, relevant_links)\n",
    "\n",
    "    final_text = \"\"\n",
    "    for partial_text in select_model_and_stream(model_choice, system_prompt, user_prompt):\n",
    "        final_text = partial_text\n",
    "        # Provide partial_text to Gradio for streaming display\n",
    "        yield final_text  \n",
    "\n",
    "    # After streaming is done, optionally save to an HTML file\n",
    "    if save_as_html and final_text.strip():\n",
    "        html_output = md_to_html(final_text)\n",
    "        filename = f\"{safe_filename}_pitch.html\"\n",
    "        try:\n",
    "            # Save the HTML file\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html_output)\n",
    "            print(f\"Pitch saved to: {filename}\")\n",
    "            \n",
    "            # Open the HTML file in a new browser window\n",
    "            import webbrowser\n",
    "            import os\n",
    "            file_path = os.path.abspath(filename)\n",
    "            webbrowser.open('file://' + file_path, new=2)  # new=2 opens in a new tab\n",
    "            \n",
    "            # Add a message to the output indicating the file was saved and opened\n",
    "            success_message = f\"\\n\\n---\\n\\nPitch saved to file: `{filename}` and opened in browser.\"\n",
    "            yield final_text + success_message\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error saving/opening file: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            yield final_text + f\"\\n\\n---\\n\\nError: {error_msg}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56b5ae4f-3862-4698-a443-594108f1d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Test a single model by calling select_model_and_stream\n",
    "    with the given system_prompt and user_prompt.\n",
    "    Prints partial chunks as they arrive, then checks final output.\n",
    "    \"\"\"\n",
    "    print(f\"--- Testing {model_name} ---\")\n",
    "    partial_chunks = []\n",
    "    \n",
    "    # Call your model streaming router\n",
    "    for partial_output in select_model_and_stream(model_name, system_prompt, user_prompt):\n",
    "        partial_chunks.append(partial_output)\n",
    "        print(\"Partial output:\")\n",
    "        print(partial_output)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    if not partial_chunks:\n",
    "        raise ValueError(f\"No output was returned by model: {model_name}\")\n",
    "\n",
    "    final_output = partial_chunks[-1]\n",
    "    if not final_output.strip():\n",
    "        raise ValueError(f\"Final output was empty for model: {model_name}\")\n",
    "\n",
    "    print(f\"\\nFinal output from {model_name}:\")\n",
    "    print(final_output)\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "def test_all_models():\n",
    "    \"\"\"\n",
    "    Test script that iterates over your three model choices\n",
    "    and ensures each can produce a non-empty response.\n",
    "    \"\"\"\n",
    "    # Replace these with your actual model names or keys\n",
    "    model_names = [\n",
    "        \"gpt-4o-mini\",\n",
    "        \"claude-3-haiku-20240307\",\n",
    "        \"deepseek-chat\"\n",
    "    ]\n",
    "\n",
    "    # Example system and user prompts\n",
    "    system_prompt = \"You are a helpful AI. Please follow instructions carefully.\"\n",
    "    user_prompt = \"Hello! Can you introduce yourself briefly?\"\n",
    "\n",
    "    for model_name in model_names:\n",
    "        try:\n",
    "            test_model(model_name, system_prompt, user_prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"Error while testing {model_name}: {e}\\n\")\n",
    "\n",
    "# Optionally run it immediately if in a .py script:\n",
    "#if __name__ == \"__main__\":\n",
    "    #test_all_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f620ca75-387f-4345-b601-2d02df1f93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_links_function():\n",
    "    # Change to a real URL you want to test\n",
    "    test_url = \"https://investor.vanguard.com\"\n",
    "    # Use one of your recognized model strings, e.g. \"GPT-4o-mini\" or \"Claude-3-haiku-20240307\"\n",
    "    test_model_choice = \"gpt-4o-mini\"\n",
    "    \n",
    "    print(f\"Testing get_links with URL={test_url} and model={test_model_choice}\")\n",
    "    try:\n",
    "        links_data = get_links(test_url, test_model_choice)\n",
    "        print(\"\\n--- get_links return value ---\")\n",
    "        print(links_data)\n",
    "        print(\"--- End of return value ---\\n\")\n",
    "        \n",
    "        if isinstance(links_data, dict):\n",
    "            print(\"Looks like we got a dict, presumably with homepage and links keys.\")\n",
    "            print(\"homepage:\", links_data.get(\"homepage\"))\n",
    "            print(\"links:\", links_data.get(\"links\", []))\n",
    "        elif isinstance(links_data, list):\n",
    "            print(\"We got a list. Here are the items:\")\n",
    "            for item in links_data:\n",
    "                print(item)\n",
    "        else:\n",
    "            print(\"Result is neither dict nor list, here's the raw output:\")\n",
    "            print(links_data)\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSONDecodeError: The response might not be valid JSON. Error details:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while testing get_links:\", str(e))\n",
    "\n",
    "# Now we call the test\n",
    "#test_get_links_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8407450c-9fc1-4de1-8685-c6f67f3b0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_all_details():\n",
    "    # Use a test URL that should return valid webpage content\n",
    "    test_url = \"https://investor.vanguard.com\"\n",
    "    # Use a test model that you expect to work (e.g., \"gpt-4o-mini\", \"claude-3-haiku-20240307\", \"deepseek-chat\")\n",
    "    test_model_choice = \"gpt-4o-mini\"\n",
    "    \n",
    "    print(f\"Testing get_all_details with URL: {test_url} and model: {test_model_choice}\")\n",
    "    \n",
    "    try:\n",
    "        # Call get_all_details with the URL and selected model\n",
    "        details = get_all_details(test_url, test_model_choice)\n",
    "        \n",
    "        print(\"----- get_all_details Output -----\")\n",
    "        print(details)\n",
    "        print(\"----- End of Output -----\")\n",
    "    \n",
    "    except json.JSONDecodeError as json_err:\n",
    "        print(\"JSONDecodeError: The output may not be valid JSON. Error details:\", json_err)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while testing get_all_details:\", str(e))\n",
    "\n",
    "# Run the test function\n",
    "#test_get_all_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3f459d5-5eed-4f32-9b5d-d7011c46d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_create_brochure():\n",
    "    # Test parameters\n",
    "    company_name = \"Vangaurd\"\n",
    "    homepage_url = \"https://investor.vanguard.com\"\n",
    "    \n",
    "    # Sample relevant links in the expected JSON structure\n",
    "    relevant_links = {\n",
    "        \"homepage\": \"https://investor.vanguard.com\",\n",
    "        \"links\": [\n",
    "            {\"type\": \"Investor Relations\", \"url\": \"https://corporate.vanguard.com/\"},\n",
    "            {\"type\": \"About Page\", \"url\": \"https://corporate.vanguard.com/content/corporatesite/us/en/corp/who-we-are/sets-us-apart/index.html\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Choose a model based on your UI choices (e.g., \"gpt-4o-mini\", \"claude-3-haiku-20240307\", or \"deepseek-chat\")\n",
    "    test_model_choice = \"gpt-4o-mini\"\n",
    "    \n",
    "    print(\"Testing create_brochure with:\")\n",
    "    print(\"Company Name:\", company_name)\n",
    "    print(\"Homepage URL:\", homepage_url)\n",
    "    print(\"Relevant Links:\", relevant_links)\n",
    "    print(\"Model Choice:\", test_model_choice)\n",
    "    \n",
    "    # Call the create_brochure function. It will stream and display the Markdown output.\n",
    "    create_brochure(company_name, homepage_url, relevant_links, test_model_choice)\n",
    "\n",
    "# Run the test function\n",
    "#test_create_brochure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dc15cbb-33c4-4401-8dd9-07c0dd2e9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gradio_stream_pitch():\n",
    "    # Test input parameters\n",
    "    company_name = \"Vangaurd\"\n",
    "    homepage_url = \"https://investor.vanguard.com\"\n",
    "    # Dummy relevant links structured as expected\n",
    "    relevant_links = {\n",
    "        \"homepage\": \"https://www.testcompany.com\",\n",
    "        \"links\": [\n",
    "            {\"type\": \"Investor Relations\", \"url\": \"https://corporate.vanguard.com/\"},\n",
    "            {\"type\": \"About Page\", \"url\": \"https://corporate.vanguard.com/content/corporatesite/us/en/corp/who-we-are/sets-us-apart/index.html\"}\n",
    "        ]\n",
    "    }\n",
    "    # Use a valid model choice; adjust as needed based on your implementation\n",
    "    model_choice = \"gpt-4o-mini\"\n",
    "    # For testing purposes, set to False so no HTML file is saved\n",
    "    save_as_html = False\n",
    "\n",
    "    print(\"Starting test of gradio_stream_pitch...\\n\")\n",
    "    \n",
    "    # Create the generator object\n",
    "    generator = gradio_stream_pitch(company_name, homepage_url, relevant_links, model_choice, save_as_html)\n",
    "    \n",
    "    prev_output = \"\"\n",
    "    # Iterate over the generator to simulate streaming output\n",
    "    for cumulative_output in generator:\n",
    "        # Print only the new portion\n",
    "        new_chunk = cumulative_output[len(prev_output):]\n",
    "        if new_chunk:  # Only print if there's something new\n",
    "            print(\"New chunk received:\")\n",
    "            print(new_chunk)\n",
    "            print(\"-\" * 40)\n",
    "        prev_output = cumulative_output\n",
    "    \n",
    "    print(\"\\nTest of gradio_stream_pitch complete.\")\n",
    "    \n",
    "# Run the test function\n",
    "#test_gradio_stream_pitch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d3ea8c8-b4d9-4178-b7be-ebed8fb81b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_get_links():\n",
    "    # Set a test URL that should return valid content\n",
    "    test_url = \"https://investor.vanguard.com/\"\n",
    "    # Set a model choice that your code recognizes (adjust if necessary)\n",
    "    test_model_choice = \"gpt-4o-mini\"\n",
    "    \n",
    "    print(f\"Testing get_links with URL: {test_url} and model: {test_model_choice}\", flush=True)\n",
    "    \n",
    "    try:\n",
    "        # Call your get_links function\n",
    "        links_output = get_links(test_url, test_model_choice)\n",
    "        print(\"----- Final JSON Output from get_links -----\", flush=True)\n",
    "        print(links_output, flush=True)\n",
    "    except json.decoder.JSONDecodeError as json_err:\n",
    "        print(\"JSONDecodeError: The output may not be valid JSON. Debug info:\", flush=True)\n",
    "        print(\"Error details:\", json_err, flush=True)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while testing get_links:\", str(e), flush=True)\n",
    "\n",
    "# Run the test function\n",
    "#test_get_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd8d2406-1cf8-4772-a543-39d2b18a86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_to_html(markdown_text):\n",
    "    \"\"\"\n",
    "    Convert Markdown text to HTML for saving to a file.\n",
    "    Uses markdown library if available, otherwise does basic conversion.\n",
    "    Also removes markdown code block fences.\n",
    "    \"\"\"\n",
    "    # Remove ```markdown and ``` delimiters if present\n",
    "    import re\n",
    "    markdown_text = re.sub(r'```markdown\\s*', '', markdown_text)\n",
    "    markdown_text = re.sub(r'```\\s*$', '', markdown_text, flags=re.MULTILINE)\n",
    "    \n",
    "    try:\n",
    "        # Try to use the markdown library if available\n",
    "        import markdown\n",
    "        html = markdown.markdown(markdown_text)\n",
    "        \n",
    "        # Wrap the HTML content in a basic HTML document structure\n",
    "        complete_html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Investment Pitch</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "        }}\n",
    "        h1, h2, h3 {{\n",
    "            color: #2c3e50;\n",
    "        }}\n",
    "        img {{\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "        }}\n",
    "        code {{\n",
    "            background-color: #f8f8f8;\n",
    "            padding: 2px 4px;\n",
    "            border-radius: 3px;\n",
    "        }}\n",
    "        pre {{\n",
    "            background-color: #f8f8f8;\n",
    "            padding: 10px;\n",
    "            border-radius: 5px;\n",
    "            overflow-x: auto;\n",
    "        }}\n",
    "        table {{\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "        }}\n",
    "        th, td {{\n",
    "            border: 1px solid #ddd;\n",
    "            padding: 8px;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #f2f2f2;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    {html}\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "        return complete_html\n",
    "        \n",
    "    except ImportError:\n",
    "        # Fallback for basic conversion if markdown library is not available\n",
    "        import re\n",
    "        \n",
    "        # Basic conversion rules\n",
    "        html = markdown_text\n",
    "        # Headers\n",
    "        html = re.sub(r'^# (.*?)$', r'<h1>\\1</h1>', html, flags=re.MULTILINE)\n",
    "        html = re.sub(r'^## (.*?)$', r'<h2>\\1</h2>', html, flags=re.MULTILINE)\n",
    "        html = re.sub(r'^### (.*?)$', r'<h3>\\1</h3>', html, flags=re.MULTILINE)\n",
    "        \n",
    "        # Bold and italic\n",
    "        html = re.sub(r'\\*\\*(.*?)\\*\\*', r'<strong>\\1</strong>', html)\n",
    "        html = re.sub(r'\\*(.*?)\\*', r'<em>\\1</em>', html)\n",
    "        \n",
    "        # Lists\n",
    "        html = re.sub(r'^- (.*?)$', r'<li>\\1</li>', html, flags=re.MULTILINE)\n",
    "        html = re.sub(r'(<li>.*?</li>\\n)+', r'<ul>\\g<0></ul>', html, flags=re.DOTALL)\n",
    "        \n",
    "        # Links\n",
    "        html = re.sub(r'\\[(.*?)\\]\\((.*?)\\)', r'<a href=\"\\2\">\\1</a>', html)\n",
    "        \n",
    "        # Images\n",
    "        html = re.sub(r'!\\[(.*?)\\]\\((.*?)\\)', r'<img src=\"\\2\" alt=\"\\1\">', html)\n",
    "        \n",
    "        # Paragraphs\n",
    "        html = re.sub(r'\\n\\n(.*?)\\n\\n', r'<p>\\1</p>\\n\\n', html, flags=re.DOTALL)\n",
    "        \n",
    "        # Wrap in HTML document\n",
    "        complete_html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Investment Pitch</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    {html}\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "        return complete_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2779fa82-a1b2-4f8a-add3-b2840e398979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gradio_app():\n",
    "    with gr.Blocks(css=\"\"\"\n",
    "    #title {\n",
    "        text-align: center;\n",
    "        font-size: 26px;\n",
    "        font-weight: bold;\n",
    "        margin-bottom: 0.8rem;\n",
    "    }\n",
    "    #subtitle {\n",
    "        text-align: center;\n",
    "        font-size: 16px;\n",
    "        margin-top: 0;\n",
    "        color: #666;\n",
    "    }\n",
    "    .company-logo {\n",
    "        max-width: 200px;\n",
    "        display: block;\n",
    "        margin: 0 auto;\n",
    "    }\n",
    "    \"\"\") as demo:\n",
    "\n",
    "        gr.Markdown(\n",
    "    \"\"\"\n",
    "    <div id='title'>AI Trading & Investment Analysis</div>\n",
    "    <div id='subtitle'>Generate data-driven company pitches and relevant links.</div>\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "        # Match the model dropdown options to the actual model names used in the code\n",
    "        model_options = [\n",
    "            \"gpt-4o-mini\",           # OpenAI model\n",
    "            \"claude-3-haiku-20240307\", # Claude model\n",
    "            \"deepseek-chat\"           # DeepSeek model\n",
    "        ]\n",
    "\n",
    "        # Tab 1: Retrieve Relevant Links\n",
    "        with gr.Tab(\"1) Retrieve Links\"):\n",
    "            link_model_choice = gr.Dropdown(\n",
    "                label=\"Model for Link Retrieval\",\n",
    "                choices=model_options,\n",
    "                value=model_options[0],\n",
    "                interactive=True\n",
    "            )\n",
    "            \n",
    "            homepage_url = gr.Textbox(\n",
    "                label=\"Company Homepage URL\",\n",
    "                placeholder=\"e.g. https://www.tesla.com\",\n",
    "                lines=1\n",
    "            )\n",
    "            \n",
    "            link_output = gr.JSON(label=\"Relevant Links\", value={\"homepage\": \"\", \"links\": []}, visible=True)\n",
    "            \n",
    "            retrieve_button = gr.Button(\"Retrieve Links\")\n",
    "            link_status = gr.Markdown(label=\"Status\")\n",
    "\n",
    "        # Tab 2: Create Trading Pitch\n",
    "        with gr.Tab(\"2) Create Pitch\"):\n",
    "            pitch_model_choice = gr.Dropdown(\n",
    "                label=\"Model for Pitch Creation\",\n",
    "                choices=model_options,\n",
    "                value=model_options[0],\n",
    "                interactive=True\n",
    "            )\n",
    "            \n",
    "            save_as_html_checkbox = gr.Checkbox(\n",
    "                label=\"Save final pitch as HTML?\",\n",
    "                value=True\n",
    "            )\n",
    "            \n",
    "            company_name_input = gr.Textbox(\n",
    "                label=\"Company Name\",\n",
    "                lines=1,\n",
    "                placeholder=\"e.g. Tesla Inc.\"\n",
    "            )\n",
    "            \n",
    "            # Add a preview for the company logo\n",
    "            with gr.Row():\n",
    "                logo_preview = gr.Image(label=\"Company Logo Preview\", visible=False)\n",
    "                logo_status = gr.Markdown(visible=False)\n",
    "            \n",
    "            # Use HTML instead of Markdown for better rendering\n",
    "            pitch_output = gr.HTML(label=\"Investment Pitch\")\n",
    "            generate_button = gr.Button(\"Generate Trading Pitch\")\n",
    "\n",
    "        # Step 1 function - enhanced with better error handling\n",
    "        def retrieve_links_fn(url, model):\n",
    "            if not url:\n",
    "                return {\"homepage\": \"\", \"links\": []}, \"Please enter a URL\"\n",
    "            \n",
    "            if not url.startswith(\"http\"):\n",
    "                url = \"https://\" + url\n",
    "            \n",
    "            try:\n",
    "                result = get_links(url, model)\n",
    "                return result, f\"Successfully retrieved links from {url}\"\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error retrieving links: {str(e)}\"\n",
    "                print(error_msg)\n",
    "                return {\"homepage\": url, \"links\": []}, error_msg\n",
    "\n",
    "        # Function to preview logo when URL changes\n",
    "        def update_logo_preview(url):\n",
    "            if not url:\n",
    "                return None, \"Enter a URL to preview the logo\"\n",
    "            \n",
    "            domain = urlparse(url).netloc\n",
    "            if not domain:\n",
    "                return None, \"Invalid URL\"\n",
    "                \n",
    "            logo_url = f\"https://logo.clearbit.com/{domain}\"\n",
    "            return logo_url, f\"Logo preview for {domain}\"\n",
    "        \n",
    "        # Connect URL input to logo preview\n",
    "        homepage_url.change(\n",
    "            fn=update_logo_preview,\n",
    "            inputs=homepage_url,\n",
    "            outputs=[logo_preview, logo_status]\n",
    "        )\n",
    "        \n",
    "        retrieve_button.click(\n",
    "            fn=retrieve_links_fn,\n",
    "            inputs=[homepage_url, link_model_choice],\n",
    "            outputs=[link_output, link_status]\n",
    "        )\n",
    "\n",
    "        # Step 2 function (streaming with HTML output)\n",
    "        def generate_pitch_fn(company_name, url, link_list, model_choice, save_as_html):\n",
    "            # link_list is the JSON from the previous step\n",
    "            if not company_name or not url:\n",
    "                yield \"Please provide both a Company Name and a Homepage URL.\"\n",
    "                return\n",
    "\n",
    "            # Make sure we're working with the right structure\n",
    "            if isinstance(link_list, dict) and \"links\" in link_list:\n",
    "                links = link_list[\"links\"]\n",
    "                homepage = link_list.get(\"homepage\", url)\n",
    "            elif isinstance(link_list, list):\n",
    "                links = link_list\n",
    "                homepage = url\n",
    "            else:\n",
    "                links = []\n",
    "                homepage = url\n",
    "            \n",
    "            # Extract domain for logo\n",
    "            domain = urlparse(homepage).netloc\n",
    "            \n",
    "            # Print debug info to help with troubleshooting\n",
    "            print(f\"Generating pitch for {company_name} ({homepage})\")\n",
    "            print(f\"Using model: {model_choice}\")\n",
    "            print(f\"Links: {links}\")\n",
    "\n",
    "            # Prepare the user prompt for the model\n",
    "            user_prompt = get_brochure_user_prompt(company_name, homepage, domain, links)\n",
    "\n",
    "            # Stream directly from the model and convert to HTML\n",
    "            markdown_content = \"\"\n",
    "            for partial_content in select_model_and_stream(\n",
    "                model_choice=model_choice,\n",
    "                system_prompt=system_prompt,\n",
    "                user_prompt=user_prompt\n",
    "            ):\n",
    "                # Clean up markdown code block markers\n",
    "                import re\n",
    "                cleaned_text = re.sub(r'```markdown\\s*', '', partial_content)\n",
    "                cleaned_text = re.sub(r'```\\s*$', '', cleaned_text, flags=re.MULTILINE)\n",
    "                \n",
    "                # Convert to HTML for better rendering\n",
    "                html_content = md_to_html(cleaned_text)\n",
    "                yield html_content\n",
    "                markdown_content = cleaned_text  # Save for file output\n",
    "\n",
    "            # After streaming is done, optionally save to an HTML file\n",
    "            if save_as_html and markdown_content.strip():\n",
    "                # Create a safe filename\n",
    "                safe_filename = re.sub(r'[\\\\/*?:\"<>|]', \"_\", company_name.strip() if company_name.strip() else domain)\n",
    "                safe_filename = safe_filename.replace(' ', '_')\n",
    "                \n",
    "                html_output = md_to_html(markdown_content)\n",
    "                filename = f\"{safe_filename}_pitch.html\"\n",
    "                try:\n",
    "                    # Save the HTML file\n",
    "                    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(html_output)\n",
    "                    print(f\"Pitch saved to: {filename}\")\n",
    "                    \n",
    "                    # Open the HTML file in a new browser window\n",
    "                    import webbrowser\n",
    "                    import os\n",
    "                    file_path = os.path.abspath(filename)\n",
    "                    webbrowser.open('file://' + file_path, new=2)  # new=2 opens in a new tab\n",
    "                    \n",
    "                    # Add a message to the final HTML output\n",
    "                    success_html = html_output + f\"\"\"\n",
    "                    <div style=\"margin-top: 30px; padding: 10px; background-color: #e6f7e6; border: 1px solid #28a745; border-radius: 5px;\">\n",
    "                        <p>✅ Pitch saved to file: <code>{filename}</code> and opened in browser.</p>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                    yield success_html\n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Error saving/opening file: {str(e)}\"\n",
    "                    print(error_msg)\n",
    "                    \n",
    "                    # Add error message to the HTML output\n",
    "                    error_html = html_output + f\"\"\"\n",
    "                    <div style=\"margin-top: 30px; padding: 10px; background-color: #f8d7da; border: 1px solid #dc3545; border-radius: 5px;\">\n",
    "                        <p>❌ Error: {error_msg}</p>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                    yield error_html\n",
    "\n",
    "        generate_button.click(\n",
    "            fn=generate_pitch_fn,\n",
    "            inputs=[company_name_input, homepage_url, link_output, pitch_model_choice, save_as_html_checkbox],\n",
    "            outputs=pitch_output\n",
    "        )\n",
    "\n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d2fd537-ba4b-4763-961c-1168d57f2168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* Running on public URL: https://6b59b525826e78dd95.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6b59b525826e78dd95.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = build_gradio_app()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e46e47-9a93-4703-a32a-16b0e1d9710c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
